{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9c3c26",
   "metadata": {},
   "source": [
    "# Oeffikator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209f649f",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We start off with global varibale and function definition and important imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8825574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f165cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import datetime\n",
    "import geopy.distance\n",
    "import json\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from requesters.bvg_rest_requester import BVGRestRequester\n",
    "from requesters.oeffi_requester import OeffiRequester\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from point_iterator.grid_point_iterator import GridPointIterator\n",
    "from point_iterator.triangular_iterator_interface import TriangularPointIterator\n",
    "from scipy.spatial import Delaunay\n",
    "# from TimeTransformer import TimeTransformer\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c87ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = datetime.datetime.today() + datetime.timedelta(days=1)\n",
    "while DAY.weekday() != 0:\n",
    "    DAY += datetime.timedelta(1)\n",
    "cdict = {\n",
    "    \"red\": ((0.0, 0.0, 0.0), (0.5, 0.0, 0.0), (1.0, 1.0, 1.0)),\n",
    "    \"blue\": ((0.0, 0.0, 0.0), (1.0, 0.0, 0.0)),\n",
    "    \"green\": ((0.0, 0.0, 1.0), (0.5, 0.0, 0.0), (1.0, 0.0, 0.0)),\n",
    "}\n",
    "CMAP = mcolors.LinearSegmentedColormap(\"my_colormap\", cdict, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(x1, y1, x2, y2):\n",
    "    return geopy.distance.distance((x1, y1), (x2, y2)).km\n",
    "\n",
    "\n",
    "def to_BVG_sdt(x: float) -> int:\n",
    "    return int(x * 10e5)\n",
    "\n",
    "\n",
    "async def start_async_process(requesters, origin, destinations, starting_date):\n",
    "    amount_of_workers = len(destinations)\n",
    "    journeys = []\n",
    "    with ThreadPoolExecutor(max_workers=amount_of_workers) as executor:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        responses = [\n",
    "            loop.run_in_executor(\n",
    "                executor,\n",
    "                requesters[i % len(requesters)].get_journey,\n",
    "                *(\n",
    "                    origin,\n",
    "                    {\n",
    "                        \"longitude\": str(destinations[i][0]),\n",
    "                        \"latitude\": str(destinations[i][1]),\n",
    "                        \"address\": \"placeholder\",\n",
    "                    },\n",
    "                    starting_date,\n",
    "                )\n",
    "            )\n",
    "            for i in range(amount_of_workers)\n",
    "        ]\n",
    "        for journey in await asyncio.gather(*responses):\n",
    "            journeys.append(journey)\n",
    "    return journeys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cf3f32",
   "metadata": {},
   "source": [
    "## Crawl Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d9a6fb",
   "metadata": {},
   "source": [
    "Let's define some parameter first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b203f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "requester1 = BVGRestRequester()\n",
    "AUTHKEY = \"\"\n",
    "assert AUTHKEY != \"\", \"Seems like you forgot to include the authkey here. Wondering where to find a key? You can find some unsecurely stored on open-source github repos.\"\n",
    "requester2 = OeffiRequester(AUTHKEY)\n",
    "requesters = [requester1, requester2]\n",
    "query = \"Hohenstauffenstra√üe 59, Berlin\"\n",
    "start = requester1.query_location(query)\n",
    "print(\"We gonne use following address: \" + start[\"address\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9534c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = str(to_BVG_sdt(start[\"longitude\"])) + \"_\" + str(to_BVG_sdt(start[\"latitude\"])) + \".csv\"\n",
    "# in format left, right, bottom, top\n",
    "# or xmin, xmax, ymin, ymax\n",
    "bounding_box = (13.2756, 13.4892, 52.4677, 52.5532)\n",
    "step_size_x = 0.02\n",
    "step_size_y = step_size_x / 2\n",
    "\n",
    "length = len(np.arange(bounding_box[0], bounding_box[1], step_size_x)) * len(\n",
    "    np.arange(bounding_box[2], bounding_box[3], step_size_y)\n",
    ")\n",
    "print(\"Amount of requests: \", length)\n",
    "print(\"Estimated time serial: \" + str(int(length / 38)) + \"min\")\n",
    "print(\"Estimated time parallel: \" + str(int(length / 138)) + \"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debd9fc3",
   "metadata": {},
   "source": [
    "## Parallel computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43beb479",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_threads = 8\n",
    "duration = 20  # minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5fd62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "destination_i = 0\n",
    "df = pd.DataFrame(columns=[\"longitude\", \"latitude\", \"Time\"])\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "\n",
    "grid_point_iterator = GridPointIterator(bounding_box, 3)\n",
    "while grid_point_iterator.has_points_remaining():\n",
    "    points = [next(grid_point_iterator) for _ in range(parallel_threads) if grid_point_iterator.has_points_remaining()]\n",
    "    loop = asyncio.get_event_loop()\n",
    "    journeys = asyncio.ensure_future(start_async_process(requesters, start, points, DAY))\n",
    "    loop.run_until_complete(journeys)\n",
    "\n",
    "    for journey in journeys.result():\n",
    "        destination_i += 1\n",
    "        i += 1\n",
    "        df.loc[i] = [\n",
    "            float(journey[\"destination\"][\"longitude\"]),\n",
    "            float(journey[\"destination\"][\"latitude\"]),\n",
    "            journey[\"arrivalTime\"],\n",
    "        ]\n",
    "    print(f\"So far {i} points were generated of which {destination_i} are destinations.\")\n",
    "\n",
    "\n",
    "time_taken_total = datetime.datetime.now() - start_time\n",
    "print(\"This took us:\")\n",
    "print(time_taken_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fbbc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "triangular_point_iterator = TriangularPointIterator(np.array(list(zip(df[\"longitude\"], df[\"latitude\"]))))\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "round_time = datetime.datetime.now()\n",
    "while datetime.datetime.now() - start_time < datetime.timedelta(minutes=duration):\n",
    "    # while destination_i < 48:\n",
    "    available_requesters = [requester for requester in requesters if not requester.has_reached_request_limit()]\n",
    "    for requester in available_requesters:\n",
    "        print(requester, len(requester.past_requests))\n",
    "\n",
    "    if available_requesters:\n",
    "        triangular_point_iterator.points = np.array(list(zip(df[\"longitude\"], df[\"latitude\"])))\n",
    "        points = [next(triangular_point_iterator) for _ in range(parallel_threads)]\n",
    "\n",
    "        # Run asychnronous requests\n",
    "        loop = asyncio.get_event_loop()\n",
    "        journeys = asyncio.ensure_future(start_async_process(available_requesters, start, points, DAY))\n",
    "        loop.run_until_complete(journeys)\n",
    "\n",
    "        for journey in journeys.result():\n",
    "            destination_i += 1\n",
    "            if journey[\"stopovers\"] != None:\n",
    "                for stop in journey[\"stopovers\"]:\n",
    "                    i += 1\n",
    "                    df.loc[i] = [stop[\"longitude\"], stop[\"latitude\"], stop[\"time\"]]\n",
    "            i += 1\n",
    "            df.loc[i] = [\n",
    "                float(journey[\"destination\"][\"longitude\"]),\n",
    "                float(journey[\"destination\"][\"latitude\"]),\n",
    "                journey[\"arrivalTime\"],\n",
    "            ]\n",
    "    else:\n",
    "        print(\"All requesters have reached there request threshold. Sleeping ...\")\n",
    "        time.sleep(2)\n",
    "\n",
    "    if datetime.datetime.now() - round_time > datetime.timedelta(seconds=60):\n",
    "        df = df.drop_duplicates()\n",
    "        df.to_csv(\"results/locations/new_\" + file_name, index=True, header=False)\n",
    "        round_time = datetime.datetime.now()\n",
    "\n",
    "    print(f\"So far {i} points were generated of which {destination_i} are destinations.\")\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "df.to_csv(\"results/locations/new_\" + file_name, index=True, header=False)\n",
    "\n",
    "time_taken_total = datetime.datetime.now() - start_time\n",
    "print(\"This took us:\")\n",
    "print(time_taken_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a706d2",
   "metadata": {},
   "source": [
    "Running the requests asynchonously which speeds up the requests per minute up to > 200."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe4b780",
   "metadata": {},
   "source": [
    "## Linear Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aad915",
   "metadata": {},
   "source": [
    "And now let's get the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dae912",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "destination_i = 0\n",
    "df = pd.DataFrame(columns=[\"X\", \"Y\", \"Time\"])\n",
    "start_time = datetime.datetime.now()\n",
    "for x in np.arange(bounding_box[0], bounding_box[1], step_size_x):\n",
    "    for y in np.arange(bounding_box[2], bounding_box[3], step_size_y):\n",
    "        destination_i += 1\n",
    "        destination = {\"longitude\": str(x), \"latitude\": str(y), \"address\": \"placeholder\"}\n",
    "        print(destination_i / length * 100, \"% Fortschritt, es fehlen\", length - destination_i)\n",
    "        print(\"Current Destination: \" + str(x) + \", \" + str(y))\n",
    "        #try:\n",
    "            # time.sleep(60/100)\n",
    "        journey = requester.get_journey(start, destination, DAY)\n",
    "        for stop in journey[\"stopovers\"]:\n",
    "            i += 1\n",
    "            df.loc[i] = [stop[\"longitude\"], stop[\"latitude\"], stop[\"time\"]]\n",
    "        i += 1\n",
    "        df.loc[i] = [\n",
    "            journey[\"destination\"][\"longitude\"],\n",
    "            journey[\"destination\"][\"latitude\"],\n",
    "            journey[\"arrivalTime\"],\n",
    "        ]\n",
    "        #except (ValueError, KeyError):\n",
    "        #    df.loc[i] = [destination[\"longitude\"], destination[\"latitude\"], \"error\"]\n",
    "        #    continue\n",
    "\n",
    "        if datetime.datetime.now() - start_time > datetime.timedelta(seconds=32):\n",
    "            df = df.drop_duplicates()\n",
    "            df.to_csv(\"results/locations/\" + file_name, index=True, header=False)\n",
    "            start_time = datetime.datetime.now()\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "df.to_csv(\"results/locations/\" + file_name, index=True, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb494ce9",
   "metadata": {},
   "source": [
    "And one alternative method of computing the map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5594b3",
   "metadata": {},
   "source": [
    "(Different Method to generate directions https://stackoverflow.com/questions/57539749/find-out-centre-of-the-most-dense-region-in-a-scatter-plot )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7810d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a gaussian kde on a regular grid of nbins x nbins over data extents\n",
    "# k = kde.gaussian_kde(data.T)\n",
    "# xi, yi = np.mgrid[x.min():x.max():nbins*1j, y.min():y.max():nbins*1j]\n",
    "# zi = k(np.vstack([xi.flatten(), yi.flatten()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0645887c",
   "metadata": {},
   "source": [
    "Time to get the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b54376",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c24a91",
   "metadata": {},
   "source": [
    "Let's read data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7114995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = requester1.query_location(query)\n",
    "file_name_plottting = str(to_BVG_sdt(start[\"longitude\"])) + \"_\" + str(to_BVG_sdt(start[\"latitude\"])) + \".csv\"\n",
    "df = pd.read_csv(\n",
    "    \"results/locations/new_\" + file_name_plottting,\n",
    "    sep=\",\",\n",
    "    index_col=0,\n",
    "    names=[\"X\", \"Y\", \"Time\"],\n",
    "    na_values=\"None\",\n",
    "    dtype={\"df\": np.float32, \"Y\": np.float32, \"Time\": str},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5eac6abd",
   "metadata": {},
   "source": [
    "Format the time from datetime formate to simple seconds (integer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d729a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.strptime(\"12000\", \"%H%M%S\")\n",
    "max_trip_time = 120 \n",
    "\n",
    "df = df.dropna()\n",
    "df.drop(df[df[\"Time\"] == \"error\"].index, inplace=True)\n",
    "df.drop(df[~df[\"Time\"].str.match(r\"(\\b\\d{6}\\b)\", na=False)].index, inplace=True)\n",
    "# df.loc[:, :] = df[df[\"Time\"] != \"error\"]\n",
    "# df.loc[:, :] = df[df[\"Time\"].str.match(r\"(\\b\\d{6}\\b)\", na=False)]  # Remove wrong time formate\n",
    "df.loc[:, \"Time\"] = pd.to_datetime(df[\"Time\"], format=\"%H%M%S\")\n",
    "df.loc[:, \"Time\"] = df[\"Time\"] - start_time\n",
    "df.loc[:, \"Time\"] = df[\"Time\"].dt.total_seconds() / 60\n",
    "df.drop(df[df[\"Time\"] < 0].index, inplace=True)  # drop all items where time is negative\n",
    "df.drop(df[df[\"Time\"] > max_trip_time].index, inplace=True)  # drop all items where time is negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90b3784",
   "metadata": {},
   "source": [
    "It's time to plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd360e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the start location coordinates from the file name\n",
    "start_location = tuple([int(coordinate) * 10e-7 for coordinate in file_name_plottting[:-4].split(\"_\")])\n",
    "# get the bounding box from the location\n",
    "bounding_box_locations = (min(df[\"X\"]), max(df[\"X\"]), min(df[\"Y\"]), max(df[\"Y\"]))\n",
    "# sets hard coded for the map \"map_berlin_A.png\"\n",
    "bounding_box_map = (13.272, 13.491, 52.456, 52.563)\n",
    "map = plt.imread(\"maps/map_berlin_A.png\")\n",
    "# define the amount of color levels should be there\n",
    "levels = np.linspace(np.min(df[\"Time\"]), np.max(df[\"Time\"]), 32)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 18))\n",
    "ax.set_xlim(bounding_box[0], bounding_box[1])\n",
    "ax.set_ylim(bounding_box[2], bounding_box[3])\n",
    "ax.tricontourf(df[\"X\"], df[\"Y\"], df[\"Time\"], levels=levels, alpha=0.5, cmap=CMAP, antialiased=True)\n",
    "# Displaying destination locations\n",
    "# ax.scatter(df[\"X\"], df[\"Y\"], alpha=0.5, color = \"brown\")\n",
    "\n",
    "# \"aspect=1.65\" as a magic number\n",
    "ax.imshow(map, extent=bounding_box_map, aspect=1.65)\n",
    "# plot the starting position\n",
    "ax.plot(start_location[0], start_location[1], marker=\"*\", markersize=20, color=\"tab:orange\")\n",
    "\n",
    "plt.savefig(f\"results/images/map_{query}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db6da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"results/images/map_berlin_sWedding.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e3b3e7",
   "metadata": {},
   "source": [
    "## Creating a map\n",
    "This code is copied from following website: http://bigmap.osmz.ru/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c7a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# Generated by BigMap 2. Permalink: http://bigmap.osmz.ru/bigmap.php?xmin=17592&xmax=17611&ymin=10740&ymax=10755&zoom=15&scale=256&tiles=osm-de\n",
    "\n",
    "import io, urllib.request, datetime, time, re, random\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# ^^^^^^ install \"python-pillow\" package | pip install Pillow | easy_install Pillow\n",
    "\n",
    "(zoom, xmin, ymin, xmax, ymax) = (15, 17592, 10740, 17611, 10755)\n",
    "layers = [\"https://{abc}.tile.openstreetmap.de/tiles/osmde/!z/!x/!y.png\"]\n",
    "attribution = \"Map data (c) OpenStreetMap, Tiles (c) OSM DE\"\n",
    "xsize = xmax - xmin + 1\n",
    "ysize = ymax - ymin + 1\n",
    "tilesize = 256\n",
    "\n",
    "resultImage = Image.new(\"RGBA\", (xsize * tilesize, ysize * tilesize), (0, 0, 0, 0))\n",
    "counter = 0\n",
    "for x in range(xmin, xmax + 1):\n",
    "    for y in range(ymin, ymax + 1):\n",
    "        for layer in layers:\n",
    "            url = layer.replace(\"!x\", str(x)).replace(\"!y\", str(y)).replace(\"!z\", str(zoom))\n",
    "            match = re.search(\"{([a-z0-9]+)}\", url)\n",
    "            if match:\n",
    "                url = url.replace(match.group(0), random.choice(match.group(1)))\n",
    "            print(url, \"... \")\n",
    "            try:\n",
    "                req = urllib.request.Request(url, headers={\"User-Agent\": \"BigMap/2.0\"})\n",
    "                tile = urllib.request.urlopen(req).read()\n",
    "            except Exception as e:\n",
    "                print(\"Error\", e)\n",
    "                continue\n",
    "            image = Image.open(io.BytesIO(tile))\n",
    "            resultImage.paste(image, ((x - xmin) * tilesize, (y - ymin) * tilesize), image.convert(\"RGBA\"))\n",
    "            counter += 1\n",
    "            if counter == 10:\n",
    "                time.sleep(2)\n",
    "                counter = 0\n",
    "\n",
    "draw = ImageDraw.Draw(resultImage)\n",
    "draw.text((5, ysize * tilesize - 15), attribution, (0, 0, 0))\n",
    "del draw\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "outputFileName = \"maps/map_Berlin_A_high.png\"  # % (zoom, now.year % 100, now.month, now.day, now.hour, now.minute)\n",
    "resultImage.save(outputFileName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d8a49a75ee7a4487a0348e6a8a0040cbb35b2e502927d00e0606738785a45890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
